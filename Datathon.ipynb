{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685b4a5f-b4d6-45d9-aa99-2fd27b613899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Datathon Dataset.csv\")\n",
    "\n",
    "def correct_misaligned_data(df):\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            pd.to_datetime(row[\"Date\"])\n",
    "        except Exception:\n",
    "            df.at[index, \"Infrastructure_Machineries\"] = row[\"Date\"]\n",
    "            df.at[index, \"Date\"] = \"\"\n",
    "\n",
    "    return df\n",
    "\n",
    "df_corrected = correct_misaligned_data(df)\n",
    "\n",
    "df_corrected.to_csv(\"Datathon_Dataset_Corrected.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93680af-45d6-4074-a740-f541c2d71f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved as: Datathon_Dataset_Pre.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail2\\AppData\\Local\\Temp\\ipykernel_76660\\1176732941.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Infrastructure_Machineries\"].replace(\"invalid_data\", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "file_path = \"Datathon_Dataset_Corrected.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df[\"Infrastructure_Machineries\"].replace(\"invalid_data\", np.nan, inplace=True)\n",
    "\n",
    "infra_machinery_mapping = {val: idx for idx, val in enumerate(df[\"Infrastructure_Machineries\"].dropna().unique())}\n",
    "df[\"Infra_Machinery_Encoded\"] = df[\"Infrastructure_Machineries\"].map(infra_machinery_mapping)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "df[\"Infra_Machinery_Encoded\"] = imputer.fit_transform(df[[\"Infra_Machinery_Encoded\"]])\n",
    "\n",
    "reverse_mapping = {v: k for k, v in infra_machinery_mapping.items()}\n",
    "df[\"Infrastructure_Machineries\"] = df[\"Infra_Machinery_Encoded\"].round().map(reverse_mapping)\n",
    "\n",
    "df.drop(columns=[\"Infra_Machinery_Encoded\"], inplace=True)\n",
    "\n",
    "output_file_path = \"Datathon_Dataset_Pre.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed dataset saved as: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f5fc2c-7036-441f-a3de-653c023145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Market_Share'] = df['Market_Share'].replace(35000, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b1d624-8a42-4043-bc0e-20ab79716725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Un_Named</th>\n",
       "      <th>Date</th>\n",
       "      <th>Infrastructure_Machineries</th>\n",
       "      <th>Daily_Sales _Percentage</th>\n",
       "      <th>Daily_Sales_Quantity</th>\n",
       "      <th>Market_Share</th>\n",
       "      <th>Political</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Customer_Id</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skid Steer Loaders</td>\n",
       "      <td>-0.034464</td>\n",
       "      <td>3534</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST00001</td>\n",
       "      <td>Sherrichester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Excavators(crawler)</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST00002</td>\n",
       "      <td>North Ryanstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Loaders (Wheeled)</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST00003</td>\n",
       "      <td>South Christophermouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Skid Steer Loaders</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST00004</td>\n",
       "      <td>Juliashire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Compactors</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST00005</td>\n",
       "      <td>Davidberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skid Steer Loaders</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST02191</td>\n",
       "      <td>East Dominiqueshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2191</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Excavators(crawler)</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST02192</td>\n",
       "      <td>Troyside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2192</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Loaders (Wheeled)</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST02193</td>\n",
       "      <td>Dodsonport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2193</td>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Skid Steer Loaders</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST02194</td>\n",
       "      <td>North Johnland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2194</td>\n",
       "      <td>4</td>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>Compactors</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.56</td>\n",
       "      <td>CUST02195</td>\n",
       "      <td>North Miguel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Un_Named      Date Infrastructure_Machineries  \\\n",
       "0              0         0       NaN         Skid Steer Loaders   \n",
       "1              1         1  1/1/2019        Excavators(crawler)   \n",
       "2              2         2  1/1/2019          Loaders (Wheeled)   \n",
       "3              3         3  1/1/2019         Skid Steer Loaders   \n",
       "4              4         4  1/1/2019                 Compactors   \n",
       "...          ...       ...       ...                        ...   \n",
       "2190        2190         0       NaN         Skid Steer Loaders   \n",
       "2191        2191         1  1/1/2019        Excavators(crawler)   \n",
       "2192        2192         2  1/1/2019          Loaders (Wheeled)   \n",
       "2193        2193         3  1/1/2019         Skid Steer Loaders   \n",
       "2194        2194         4  1/1/2019                 Compactors   \n",
       "\n",
       "      Daily_Sales _Percentage  Daily_Sales_Quantity  Market_Share  Political  \\\n",
       "0                   -0.034464                  3534            35          1   \n",
       "1                    0.034464                    80            35          1   \n",
       "2                    0.034464                    70            35          1   \n",
       "3                    0.034464                    70            35          1   \n",
       "4                    0.034464                    68            35          1   \n",
       "...                       ...                   ...           ...        ...   \n",
       "2190                 0.034464                    79            35          1   \n",
       "2191                 0.034464                    67            35          1   \n",
       "2192                 0.034464                    70            35          1   \n",
       "2193                 0.034464                    89            35          1   \n",
       "2194                 0.034464                    63            35          1   \n",
       "\n",
       "      Marketing   Budget Customer_Id                  Region  \n",
       "0             1  5000.56   CUST00001           Sherrichester  \n",
       "1             1  5000.56   CUST00002          North Ryanstad  \n",
       "2             1  5000.56   CUST00003  South Christophermouth  \n",
       "3             1  5000.56   CUST00004              Juliashire  \n",
       "4             1  5000.56   CUST00005               Davidberg  \n",
       "...         ...      ...         ...                     ...  \n",
       "2190          1  5000.56   CUST02191     East Dominiqueshire  \n",
       "2191          1  5000.56   CUST02192                Troyside  \n",
       "2192          1  5000.56   CUST02193              Dodsonport  \n",
       "2193          1  5000.56   CUST02194          North Johnland  \n",
       "2194          1  5000.56   CUST02195            North Miguel  \n",
       "\n",
       "[2195 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21301855-7bad-4b05-892b-1432d986a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with negative Daily_Sales_Quantity: 73\n"
     ]
    }
   ],
   "source": [
    "negative_count = (df['Daily_Sales_Quantity'] < 0).sum()\n",
    "print(f\"Number of rows with negative Daily_Sales_Quantity: {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4937b6-0566-4e2d-9b46-c032a66053bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                          Daily_Sales_Quantity  Daily_Sales _Percentage\n",
      "Daily_Sales_Quantity                 1.000000                -0.067742\n",
      "Daily_Sales _Percentage             -0.067742                 1.000000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Daily_Sales_Percentage'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, correlation)\n\u001b[0;32m     13\u001b[0m train_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily_Sales_Quantity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m X \u001b[38;5;241m=\u001b[39m train_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily_Sales_Percentage\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily_Sales_Quantity\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[0;32m     18\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Daily_Sales_Percentage'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#CORRELATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "correlation = df[['Daily_Sales_Quantity', 'Daily_Sales _Percentage']].corr()\n",
    "print(\"Correlation Matrix:\\n\", correlation)\n",
    "\n",
    "train_data = df[df['Daily_Sales_Quantity'] <= 3000]\n",
    "\n",
    "X = train_data[['Daily_Sales_Percentage']]  \n",
    "y = train_data['Daily_Sales_Quantity']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "outlier_mask = df['Daily_Sales_Quantity'] > 3000 \n",
    "df.loc[outlier_mask, 'Daily_Sales_Quantity'] = model.predict(df.loc[outlier_mask, ['Daily_Sales_Percentage']])\n",
    "\n",
    "df['Daily_Sales_Quantity'] = df['Daily_Sales_Quantity'].clip(lower=1)\n",
    "\n",
    "print(\"Updated dataset with corrected values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07134c76-68a0-4d96-8465-d79476c0bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset processing complete. File saved as 'processed_file.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Processed_Datathon_Dataset.csv\") \n",
    "\n",
    "df['Daily_Sales_Quantity'] = df['Daily_Sales_Quantity'].astype(int)\n",
    "\n",
    "df['Market_Share'] = 35\n",
    "\n",
    "df.to_csv(\"Correct_Processed.csv\", index=False) \n",
    "\n",
    "print(\"Dataset processing complete. File saved as 'processed_file.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "051ab668-02a7-4d58-bb6f-f5e9b5007bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mail2\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
      "   ---------------------------------------- 0.0/101.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/101.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/101.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/101.7 MB 1.5 MB/s eta 0:01:10\n",
      "   ---------------------------------------- 0.8/101.7 MB 1.5 MB/s eta 0:01:10\n",
      "   ---------------------------------------- 1.0/101.7 MB 1.1 MB/s eta 0:01:28\n",
      "    --------------------------------------- 1.3/101.7 MB 1.2 MB/s eta 0:01:27\n",
      "    --------------------------------------- 1.3/101.7 MB 1.2 MB/s eta 0:01:27\n",
      "    --------------------------------------- 1.6/101.7 MB 976.0 kB/s eta 0:01:43\n",
      "    --------------------------------------- 1.6/101.7 MB 976.0 kB/s eta 0:01:43\n",
      "    --------------------------------------- 1.8/101.7 MB 959.1 kB/s eta 0:01:45\n",
      "    --------------------------------------- 2.1/101.7 MB 962.8 kB/s eta 0:01:44\n",
      "    --------------------------------------- 2.4/101.7 MB 938.7 kB/s eta 0:01:46\n",
      "    --------------------------------------- 2.4/101.7 MB 938.7 kB/s eta 0:01:46\n",
      "   - -------------------------------------- 2.6/101.7 MB 904.3 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 2.6/101.7 MB 904.3 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 2.9/101.7 MB 902.1 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 2.9/101.7 MB 902.1 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 3.1/101.7 MB 854.4 kB/s eta 0:01:56\n",
      "   - -------------------------------------- 3.4/101.7 MB 883.1 kB/s eta 0:01:52\n",
      "   - -------------------------------------- 3.4/101.7 MB 883.1 kB/s eta 0:01:52\n",
      "   - -------------------------------------- 3.7/101.7 MB 848.8 kB/s eta 0:01:56\n",
      "   - -------------------------------------- 3.7/101.7 MB 848.8 kB/s eta 0:01:56\n",
      "   - -------------------------------------- 3.9/101.7 MB 827.1 kB/s eta 0:01:59\n",
      "   - -------------------------------------- 4.2/101.7 MB 844.5 kB/s eta 0:01:56\n",
      "   - -------------------------------------- 4.5/101.7 MB 868.7 kB/s eta 0:01:52\n",
      "   -- ------------------------------------- 5.2/101.7 MB 966.0 kB/s eta 0:01:40\n",
      "   -- ------------------------------------- 6.0/101.7 MB 1.1 MB/s eta 0:01:29\n",
      "   -- ------------------------------------- 6.6/101.7 MB 1.1 MB/s eta 0:01:24\n",
      "   -- ------------------------------------- 7.6/101.7 MB 1.3 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 8.4/101.7 MB 1.4 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 9.2/101.7 MB 1.4 MB/s eta 0:01:05\n",
      "   ---- ----------------------------------- 10.5/101.7 MB 1.6 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 11.5/101.7 MB 1.7 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 12.3/101.7 MB 1.8 MB/s eta 0:00:51\n",
      "   ---- ----------------------------------- 12.6/101.7 MB 1.8 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 13.6/101.7 MB 1.8 MB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 14.4/101.7 MB 1.9 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 15.5/101.7 MB 2.0 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 16.5/101.7 MB 2.1 MB/s eta 0:00:42\n",
      "   ------ --------------------------------- 17.6/101.7 MB 2.1 MB/s eta 0:00:40\n",
      "   ------- -------------------------------- 18.9/101.7 MB 2.2 MB/s eta 0:00:37\n",
      "   -------- ------------------------------- 20.4/101.7 MB 2.4 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 21.8/101.7 MB 2.5 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 22.8/101.7 MB 2.5 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 23.9/101.7 MB 2.6 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 24.6/101.7 MB 2.6 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 24.9/101.7 MB 2.6 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 25.2/101.7 MB 2.6 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 26.5/101.7 MB 2.6 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 27.3/101.7 MB 2.6 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 27.8/101.7 MB 2.6 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 28.3/101.7 MB 2.7 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 29.1/101.7 MB 2.7 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 29.6/101.7 MB 2.7 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 30.1/101.7 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 30.7/101.7 MB 2.6 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 30.7/101.7 MB 2.6 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 31.7/101.7 MB 2.6 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 32.5/101.7 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 33.0/101.7 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 33.6/101.7 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 34.3/101.7 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 35.1/101.7 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 35.7/101.7 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 36.4/101.7 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 37.2/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.5/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.7/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 38.3/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 39.1/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 39.3/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 39.6/101.7 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 40.1/101.7 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 40.1/101.7 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 40.4/101.7 MB 2.6 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 40.6/101.7 MB 2.6 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 40.9/101.7 MB 2.6 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 41.2/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 41.4/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 41.7/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 42.2/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 42.5/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 42.5/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 43.0/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 43.0/101.7 MB 2.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 43.3/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 43.5/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 43.5/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 43.8/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 44.3/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 44.6/101.7 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 44.8/101.7 MB 2.3 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 45.1/101.7 MB 2.3 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 45.4/101.7 MB 2.3 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 45.6/101.7 MB 2.3 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 46.4/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 46.9/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 46.9/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 47.4/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 47.7/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 48.2/101.7 MB 2.3 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 49.0/101.7 MB 2.3 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 49.8/101.7 MB 2.3 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 50.3/101.7 MB 2.3 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 50.9/101.7 MB 2.3 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 51.4/101.7 MB 2.3 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 51.9/101.7 MB 2.3 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 52.7/101.7 MB 2.3 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 53.2/101.7 MB 2.3 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 54.0/101.7 MB 2.3 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 54.8/101.7 MB 2.4 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 55.3/101.7 MB 2.4 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 56.1/101.7 MB 2.4 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 56.6/101.7 MB 2.4 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 57.4/101.7 MB 2.4 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 58.2/101.7 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 58.7/101.7 MB 2.4 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 59.0/101.7 MB 2.4 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 59.5/101.7 MB 2.4 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 60.3/101.7 MB 2.4 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 61.1/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 61.6/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 62.1/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 62.7/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 62.9/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 63.2/101.7 MB 2.4 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 63.7/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 64.0/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 64.2/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 64.5/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 64.7/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 65.0/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 65.3/101.7 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 65.8/101.7 MB 2.3 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 66.1/101.7 MB 2.3 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.6/101.7 MB 2.3 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 67.1/101.7 MB 2.3 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 67.9/101.7 MB 2.4 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.7/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 68.9/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 69.7/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.0/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.0/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.0/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.8/101.7 MB 2.4 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.3/101.7 MB 2.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 71.6/101.7 MB 2.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 72.1/101.7 MB 2.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 72.4/101.7 MB 2.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 72.9/101.7 MB 2.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 73.4/101.7 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 73.9/101.7 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 74.4/101.7 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 74.7/101.7 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 75.0/101.7 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 75.0/101.7 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 75.8/101.7 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 75.8/101.7 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 76.3/101.7 MB 2.5 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 76.3/101.7 MB 2.5 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 76.8/101.7 MB 2.5 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 77.1/101.7 MB 2.5 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 77.3/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 77.6/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 77.6/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 78.1/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 78.6/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 79.2/101.7 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 80.0/101.7 MB 2.5 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 80.5/101.7 MB 2.5 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 81.3/101.7 MB 2.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 82.1/101.7 MB 2.5 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 82.8/101.7 MB 2.5 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 83.1/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 83.4/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 83.6/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 83.9/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 84.1/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 84.7/101.7 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 85.2/101.7 MB 2.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 85.5/101.7 MB 2.3 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 85.5/101.7 MB 2.3 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 86.5/101.7 MB 2.3 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 87.0/101.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 88.1/101.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 88.6/101.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 89.1/101.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 89.9/101.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 90.4/101.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 91.0/101.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 91.5/101.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.0/101.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.5/101.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.1/101.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.6/101.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.1/101.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.9/101.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.4/101.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.9/101.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 96.2/101.7 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.7/101.7 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.3/101.7 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.5/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.5/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.0/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.3/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.6/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 99.1/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.6/101.7 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  100.1/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.2/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.7/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.7/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.7/101.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.7/101.7 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.7 graphviz-0.20.3\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d36fade9-6be0-4188-9943-d3d11a46ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 8.1071\n",
      "RMSE: 9.9452\n",
      "R2 Score: 0.8642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Tele Handlers .csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Infrastructure_Machineries\", \"Customer_Id\", \"Region\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "X = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "y = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "catboost_model = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "\n",
    "catboost_model.fit(X_train, y_train)\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7728e3e3-adb6-4280-b244-c5dafc3799da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 8.0915\n",
      "RMSE: 10.3002\n",
      "R2 Score: 0.8529\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Loaders (Wheeled).csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Infrastructure_Machineries\", \"Customer_Id\", \"Region\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "A = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "b = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "A_train, A_test, b_train, b_test = train_test_split(A, b, test_size=0.2, random_state=42)\n",
    "\n",
    "Wheeled = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "Wheeled.fit(A_train, b_train)\n",
    "b_pred = Wheeled.predict(A_test)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(b_test, b_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(b_test, b_pred)),\n",
    "    \"R2 Score\": r2_score(b_test, b_pred)\n",
    "}\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75a28f60-14dd-4e82-b637-f0cf7bc4d6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 8.6772\n",
      "RMSE: 10.7546\n",
      "R2 Score: 0.8530\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Excavators(crawler).csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "C = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "d = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "C_train, C_test, d_train, d_test = train_test_split(C, d, test_size=0.2, random_state=42)\n",
    "\n",
    "Excavator = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "Excavator.fit(C_train, d_train)\n",
    "d_pred = Excavator.predict(C_test)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(d_test, d_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(d_test, d_pred)),\n",
    "    \"R2 Score\": r2_score(d_test, d_pred)\n",
    "}\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "687be7a7-ca6a-49ef-9833-25effa8dfda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 8.6708\n",
      "RMSE: 10.8444\n",
      "R2 Score: 0.8262\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Skid Steer Loaders.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "E = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "f = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "E_train, E_test, f_train, f_test = train_test_split(E, f, test_size=0.2, random_state=42)\n",
    "\n",
    "SkidSteer = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "SkidSteer.fit(E_train, f_train)\n",
    "f_pred = SkidSteer.predict(E_test)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(f_test, f_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(f_test, f_pred)),\n",
    "    \"R2 Score\": r2_score(f_test, f_pred)\n",
    "}\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c8a68b7-f960-47dd-be6a-09496c7e2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 8.2718\n",
      "RMSE: 10.4788\n",
      "R2 Score: 0.8677\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Compactors.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "G = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "h = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "G_train, G_test, h_train, h_test = train_test_split(G, h, test_size=0.2, random_state=42)\n",
    "\n",
    "Compactors = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "Compactors.fit(G_train, h_train)\n",
    "h_pred = Compactors.predict(G_test)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(h_test, h_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(h_test, h_pred)),\n",
    "    \"R2 Score\": r2_score(h_test, h_pred)\n",
    "}\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39d4fbf8-f556-433b-9a3e-88b68a7da25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Performance:\n",
      "MAE: 12.6723\n",
      "RMSE: 15.3277\n",
      "R2 Score: 0.5908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"dataset_Backhoe Loader.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "drop_columns = [\"Unnamed: 0\", \"Un_Named\", \"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]\n",
    "df_cleaned = df.drop(columns=drop_columns)\n",
    "\n",
    "I = df_cleaned.drop(columns=[\"Daily_Sales_Quantity\"])\n",
    "j = df_cleaned[\"Daily_Sales_Quantity\"]\n",
    "\n",
    "I_train, I_test, j_train, j_test = train_test_split(I, j, test_size=0.2, random_state=42)\n",
    "\n",
    "Backhoe = CatBoostRegressor(n_estimators=200, learning_rate=0.05, verbose=0, random_state=42)\n",
    "\n",
    "Backhoe.fit(I_train, j_train)\n",
    "j_pred = Backhoe.predict(I_test)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": mean_absolute_error(j_test, j_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(j_test, j_pred)),\n",
    "    \"R2 Score\": r2_score(j_test, j_pred)\n",
    "}\n",
    "\n",
    "print(\"\\nCatBoost Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "49cd2906-cfea-420b-afe7-28c1f0e34c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row 5: No model found for Tele Handlers \n",
      "Predictions: [70.33446624377049, 68.46492361106971, 69.05582887141507, 63.24749875723337, 66.72004645776296]\n",
      "Skipped Rows: [5]\n"
     ]
    }
   ],
   "source": [
    "# Collect predictions\n",
    "predictions = []\n",
    "skipped_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    infra_type = row[\"Infrastructure_Machineries\"]  # Get the infrastructure type\n",
    "    model = model_mapping.get(infra_type)  # Get the corresponding model\n",
    "\n",
    "    if model:\n",
    "        try:\n",
    "            input_data = row.drop([\"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]).values.reshape(1, -1)\n",
    "            \n",
    "            pred = model.predict(input_data)\n",
    "            predictions.append(pred[0])  # Assuming a single output per row\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting row {index}: {e}\")\n",
    "            skipped_rows.append(index)\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping row {index}: No model found for {infra_type}\")\n",
    "        skipped_rows.append(index)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Skipped Rows:\", skipped_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b13fce1b-d578-4919-b4e2-9f95a659bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70.33446624377049, 68.46492361106971, 69.05582887141507, 63.24749875723337, 66.72004645776296, 63.24749875723337]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"input_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dictionary mapping infrastructure types to their corresponding models\n",
    "model_mapping = {\n",
    "    \"Tele Handlers \": catboost_model,\n",
    "    \"Loaders (Wheeled)\": Wheeled,\n",
    "    \"Excavators(crawler)\": Excavator,\n",
    "    \"Skid Steer Loaders\": SkidSteer,\n",
    "    \"Compactors\": Compactors,\n",
    "    \"Backhoe Loader\": Backhoe,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Collect predictions\n",
    "predictions = []\n",
    "for _, row in df.iterrows():\n",
    "    infra_type = row[\"Infrastructure_Machineries\"]  # Get the infrastructure type\n",
    "    model = model_mapping.get(infra_type)  # Get the corresponding model\n",
    "    if model:\n",
    "        input_data = row.drop([\"Date\", \"Customer_Id\", \"Region\", \"Infrastructure_Machineries\"]).values.reshape(1, -1)\n",
    "\n",
    "          #drop_columns = [\"Unnamed: 0\", \"Un_Named\", ]\n",
    "\n",
    "        pred = model.predict(input_data)\n",
    "        predictions.append(pred[0])  # Assuming a single output per row\n",
    "\n",
    "print(predictions)  # List of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b0e53058-4e37-41e3-9b15-00f749ab2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_demand=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1c31426-a367-455c-8ad2-d97aa89a01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.33446624377049,\n",
       " 68.46492361106971,\n",
       " 69.05582887141507,\n",
       " 63.24749875723337,\n",
       " 66.72004645776296,\n",
       " 63.24749875723337]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69b12c44-794e-404a-a3c9-8483ae2b0746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 68, 69, 63, 67, 63]\n"
     ]
    }
   ],
   "source": [
    "max_demand = [round(x) for x in max_demand]\n",
    "\n",
    "print(max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "edd6b526-522a-419c-a9a1-7e85aaef60f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BEFORE OPTIMIZATION: Forecasted Demand\n",
      "Compactors: 70 units\n",
      "Loaders (Wheeled): 68 units\n",
      "Skid Steer Loaders: 69 units\n",
      "Backhoe Loader: 63 units\n",
      "Excavators (crawler): 67 units\n",
      "Tele Handlers: 63 units\n",
      "Total Space Needed: 6644 cubic meters\n",
      " Warning: Storage Exceeds 5000 cubic meters! Optimization required.\n",
      "\n",
      "\n",
      " AFTER OPTIMIZATION: Allocated Inventory\n",
      "Compactors: 70 units\n",
      "Loaders (Wheeled): 68 units\n",
      "Skid Steer Loaders: 69 units\n",
      "Backhoe Loader: 63 units\n",
      "Excavators (crawler): 1 units\n",
      "Tele Handlers: 63 units\n",
      " Total Space Used: 4994 cubic meters (Max: 5000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# Machine names\n",
    "\n",
    "machines = [\"Compactors\", \"Loaders (Wheeled)\", \"Skid Steer Loaders\", \"Backhoe Loader\", \"Excavators (crawler)\", \"Tele Handlers\"]\n",
    "\n",
    "# Space per machine \n",
    "spaces = [12, 20, 10, 15, 25, 18]\n",
    "\n",
    "\n",
    "# Forecasted demand (max units that might be sold)\n",
    " \n",
    "\n",
    "# Total warehouse space limit (cubic meters)\n",
    "warehouse_capacity = 5000  \n",
    "\n",
    "#  BEFORE OPTIMIZATION: Check if total space exceeds 5000 cu. meters\n",
    "total_space_needed = sum(np.array(spaces) * np.array(max_demand))\n",
    "print(\"\\n BEFORE OPTIMIZATION: Forecasted Demand\")\n",
    "for i in range(len(machines)):\n",
    "    print(f\"{machines[i]}: {max_demand[i]} units\")\n",
    "\n",
    "print(f\"Total Space Needed: {total_space_needed} cubic meters\")\n",
    "\n",
    "if total_space_needed > warehouse_capacity:\n",
    "    print(\" Warning: Storage Exceeds 5000 cubic meters! Optimization required.\\n\")\n",
    "else:\n",
    "    print(\" Storage is within limits. No need for optimization.\\n\")\n",
    "\n",
    "\n",
    "#  OPTIMIZATION USING LINEAR PROGRAMMING\n",
    "c = -np.array(max_demand)  # Convert to negative since linprog minimizes\n",
    "A = [spaces]  # Constraint: total space used must be â‰¤ 5000\n",
    "b = [warehouse_capacity]  # Space limit\n",
    "x_bounds = [(0, d) for d in max_demand]  # Each machine stock is between 0 and demand\n",
    "\n",
    "# Solve optimization\n",
    "result = linprog(c, A_ub=A, b_ub=b, bounds=x_bounds, method='highs')\n",
    "\n",
    "# Extract optimized stock levels\n",
    "optimized_inventory = np.round(result.x).astype(int)  # Convert to integer\n",
    "\n",
    "#  AFTER OPTIMIZATION: Print the adjusted inventory\n",
    "print(\"\\n AFTER OPTIMIZATION: Allocated Inventory\")\n",
    "total_optimized_space = sum(np.array(optimized_inventory) * np.array(spaces))\n",
    "\n",
    "for i in range(len(machines)):\n",
    "    print(f\"{machines[i]}: {optimized_inventory[i]} units\")\n",
    "\n",
    "print(f\" Total Space Used: {total_optimized_space} cubic meters (Max: {warehouse_capacity})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d9dd-7ce8-40d8-9b38-7a2b006316e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
